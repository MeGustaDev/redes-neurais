{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplos de ajuste sináptico - aprendizado"
      ],
      "metadata": {
        "id": "1szpNCUd4v4H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm5x8K12YHVy"
      },
      "outputs": [],
      "source": [
        "# base\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supondo f(x)=x,\n",
        "\n",
        "y = w1.x1 + w2.x2 - b\n",
        "\n",
        "fazendo y=0 e reescrevendo para x2 em termos de x1,\n",
        "\n",
        "x2 = -(w1/w2).x1 +b/w2\n",
        "\n",
        "facendo w0 = -b,"
      ],
      "metadata": {
        "id": "Ep1X56GAYk4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base\n",
        "\n",
        "# função para traçar reta\n",
        "def coord(w0,w1,w2,x1):\n",
        "  if w2 != 0:\n",
        "    return (-w0-w1*x1)/w2\n",
        "  else:\n",
        "    return 2000 # Inf"
      ],
      "metadata": {
        "id": "w7R_Oad1hnAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentos clássicos com o Perceptron / ADALINE / Regra de Hebb"
      ],
      "metadata": {
        "id": "8rtU1ZvU47mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escolha um dos datasets:"
      ],
      "metadata": {
        "id": "InqMjwhgpGdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset Iris\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
        "\n",
        "# setosa e versicolor\n",
        "y = df.iloc[0:100, 4].values\n",
        "y = np.where(y == 'Iris-setosa', -1, 1)\n",
        "\n",
        "# comps sepal e petal\n",
        "X = df.iloc[0:100, [0,2]].values\n"
      ],
      "metadata": {
        "id": "r6s7TiK3rply"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset porta lógica AND\n",
        "X = np.array([[-1,-1],[-1,1],[1,-1],[1,1]])\n",
        "y = np.array([-1,-1,-1,1])"
      ],
      "metadata": {
        "id": "VAdiAvZoxN9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confere entrada - saída\n",
        "X[0:4], y[0:4]"
      ],
      "metadata": {
        "id": "HrolgBNJaOWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cria objeto Perceptron e escolhe parâmetros do treinamento (épocas e taxa de aprendizado):"
      ],
      "metadata": {
        "id": "PA57-1z7rQ_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base\n",
        "# classe Perceptron\n",
        "\n",
        "class Perceptron(object):\n",
        "\n",
        "    def __init__(self, eta=0.1, epocas=50):\n",
        "        self.eta = eta\n",
        "        self.epocas = epocas\n",
        "        self.w_ = np.random.rand(1 + X.shape[1]) - 0.5\n",
        "\n",
        "    def treina(self, X, y):\n",
        "        self.erros_ = []\n",
        "        for _ in range(self.epocas):\n",
        "            erros = 0\n",
        "            for xi, target in zip(X, y):\n",
        "\n",
        "                # atualizacao PERCEPTRON classico\n",
        "                #atualiza = self.eta * (target - self.predict(xi))\n",
        "\n",
        "                # atualizacao abordagem ADALINE\n",
        "                atualiza = self.eta * (target - self.somat(xi))\n",
        "\n",
        "                self.w_[0] +=  atualiza * 1\n",
        "                self.w_[1:] +=  atualiza * xi\n",
        "\n",
        "                # erros PERCEPTRON\n",
        "                #erros += int(atualiza != 0.0)\n",
        "\n",
        "                # erros ADALINE\n",
        "                erros += (target - self.somat(xi))\n",
        "\n",
        "            self.erros_.append(erros)\n",
        "        return self\n",
        "\n",
        "    # supondo que cada entrada fosse outro neurônio\n",
        "    def treinaHebb(self, X, y):\n",
        "        self.erros_ = []\n",
        "        for _ in range(self.epocas):\n",
        "            erros = 0\n",
        "            for xi, target in zip(X, y):\n",
        "\n",
        "                # atualizacao PERCEPTRON - somente mesmo sinal\n",
        "                if (target * self.somat(xi)) > 0:\n",
        "                    atualiza = self.eta\n",
        "                else:\n",
        "                    atualiza = 0\n",
        "\n",
        "                self.w_[0] +=  atualiza * 1\n",
        "                self.w_[1:] +=  atualiza * xi\n",
        "\n",
        "                # erros PERCEPTRON\n",
        "                erros += int(atualiza != 0.0)\n",
        "\n",
        "            self.erros_.append(erros)\n",
        "        return self\n",
        "\n",
        "    def somat(self, X):\n",
        "        return self.w_[0] + np.dot(X, self.w_[1:])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(self.somat(X) >= 0.0, 1, -1)"
      ],
      "metadata": {
        "id": "EuFLts2WpgPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cria objeto 'rna' : um neurônio Perceptron\n",
        "rna = Perceptron(epocas=20, eta=0.01)"
      ],
      "metadata": {
        "id": "oRTWTnGNbEb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostra o classificador antes do treinamento\n",
        "print(f'Pesos iniciais: {rna.w_}')\n",
        "x1, y1 = X[y==1,0],X[y==1,1]\n",
        "x0, y0 = X[y==-1,0], X[y==-1,1]\n",
        "\n",
        "ylim = [min(min(x1) , min(x0))-1, max(max(x0) , max(x1))+1]\n",
        "x = np.linspace(ylim[0], ylim[1], 2)\n",
        "plt.scatter(x1,y1, color='blue')\n",
        "plt.scatter(x0,y0,color='red')\n",
        "plt.plot(ylim,coord(rna.w_[0],rna.w_[1],rna.w_[2], x),color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Y4qeT8amMey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testa/executa o neurônio : entrada -> saída\n",
        "rna.predict([5,1.5]), rna.predict([6,4])"
      ],
      "metadata": {
        "id": "uNuprPU8Zg7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Escolhe um tipo de treinamento:\n",
        "\n",
        "- a seleção da atualização (Perceptron clássica ou ADALINE) pode ser ajustada com 'comentários' partes do código na declaração do objeto."
      ],
      "metadata": {
        "id": "HEFYXA3fre2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# treina o neurônio\n",
        "rna.treina(X, y)\n",
        "#rna.treinaHebb(X, y)"
      ],
      "metadata": {
        "id": "V0KzaAHNxKYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Pesos depois treinamento: {rna.w_}')"
      ],
      "metadata": {
        "id": "kTE3FklkcZpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise dos resultados do treinamento (evolução do erro e visualização do classificador linear resultante)"
      ],
      "metadata": {
        "id": "1pXMEefNspg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evolução do erro\n",
        "plt.plot(range(1, len(rna.erros_)+1), rna.erros_, marker='o')\n",
        "plt.xlabel('Iterações')\n",
        "plt.ylabel('Erros de classificação')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "thfMEmTcsM4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Pesos depois treinamento [w0, w1,w2]: {rna.w_}')\n",
        "x1, y1 = X[y==1,0],X[y==1,1]\n",
        "x0, y0 = X[y==-1,0], X[y==-1,1]\n",
        "\n",
        "ylim = [min(min(x1) , min(x0))-1, max(max(x0) , max(x1))+1]\n",
        "x = np.linspace(ylim[0], ylim[1], 2)\n",
        "plt.scatter(x1,y1, color='blue')\n",
        "plt.scatter(x0,y0,color='red')\n",
        "plt.plot(ylim,coord(rna.w_[0],rna.w_[1],rna.w_[2], x),color='black')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wxty99Ywsej7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lembrem-se que, a qualquer momento, vcs podem verificar os valores atuais de uma dada variável\n",
        "rna.erros_"
      ],
      "metadata": {
        "id": "2lFmTNX8s6wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Atividade 03: Testando e entendendo os tipos de aprendizado e seus parâmetros\n",
        "\n",
        "1) Para o dataset da porta lógica AND, verifique e compare os resultados obtidos usando:\n",
        "\n",
        "*   o neurônio Perceptron com a regra de correção Delta (usando a saída do Perceptron para cálculo do erro)\n",
        "*  e o ADALINE que utiliza a somatória das estradas ponderadas como base para o ajuste dos pesos sinápticos.\n",
        "*   Verifique como a quantidade de épocas e a taxa de aprendizado (eta) influenciam no treinamento e no resultado\n",
        "*   Verifique, se for o caso, sob quais condições a regra de Hebb - método treinaHebb() - pode ser usada no aprendizado do Perceptron neste dataset\n",
        "\n",
        "2) Para o dataset da Iris (entradas: comprimentos da sépala e pétala - colunas 0 e 2), verifique e compare os resultados obtidos usando:\n",
        "\n",
        "*    o neurônio Perceptron com a regra de correção Delta (usando a saída do Perceptron para cálculo do erro)\n",
        "*  e o ADALINE que utiliza a somatória das estradas ponderadas como base para o ajuste dos pesos sinápticos.\n",
        "*   Verifique como a quantidade de épocas e a taxa de aprendizado (eta) influenciam no treinamento e resultado\n",
        "*   Verifique, se for o caso, sob quais condições a regra de Hebb pode ser usada no aprendizado do Perceptron neste dataset\n",
        "\n",
        ".\n",
        "\n",
        "**Prepare um relatório (Atividade 03 - para entregar) que apresenta os resultados dos testes e as conclusões.**\n"
      ],
      "metadata": {
        "id": "jVfv3AaAlUE1"
      }
    }
  ]
}