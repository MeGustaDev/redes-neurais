{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Info:\n",
    "Nome: Rice Dataset (Commeo and Osmancik)     \n",
    "Resumo: Um total de 3810 imagens de grãos de arroz foram tiradas de duas espécies (Cammeo e Osmancik).      \n",
    "- As imagens foram pré-processadas e certos atributos foram inferidos     \n",
    "- Sete atributos morfológicos foram obtidos para cada imagem de grão de arroz\n",
    "    - Area (integer)\n",
    "    - Perimeter (float)\n",
    "    - **Major_Axis_Length (float)** -> atributos utilizados\n",
    "    - **Minor_Axis_Length (float)** -> atributos utilizados\n",
    "    - Eccentricity (float)\n",
    "    - Extent (float)\n",
    "- Classes:\n",
    "    - Cammeo\n",
    "    - Osmancik\n",
    "\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           0           1           2          3         4      5         6  \\\n",
       "0     15231  525.578979  229.749878  85.093788  0.928882  15617  0.572896   \n",
       "1     14656  494.311005  206.020065  91.730972  0.895405  15072  0.615436   \n",
       "2     14634  501.122009  214.106781  87.768288  0.912118  14954  0.693259   \n",
       "3     13176  458.342987  193.337387  87.448395  0.891861  13368  0.640669   \n",
       "4     14688  507.166992  211.743378  89.312454  0.906691  15262  0.646024   \n",
       "...     ...         ...         ...        ...       ...    ...       ...   \n",
       "3805  11441  415.858002  170.486771  85.756592  0.864280  11628  0.681012   \n",
       "3806  11625  421.390015  167.714798  89.462570  0.845850  11904  0.694279   \n",
       "3807  12437  442.498993  183.572922  86.801979  0.881144  12645  0.626739   \n",
       "3808   9882  392.296997  161.193985  78.210480  0.874406  10097  0.659064   \n",
       "3809  11434  404.709991  161.079269  90.868195  0.825692  11591  0.802949   \n",
       "\n",
       "             7  \n",
       "0       Cammeo  \n",
       "1       Cammeo  \n",
       "2       Cammeo  \n",
       "3       Cammeo  \n",
       "4       Cammeo  \n",
       "...        ...  \n",
       "3805  Osmancik  \n",
       "3806  Osmancik  \n",
       "3807  Osmancik  \n",
       "3808  Osmancik  \n",
       "3809  Osmancik  \n",
       "\n",
       "[3810 rows x 8 columns]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rice.csv', header=None)\n",
    "y = df.iloc[0:, 7].values\n",
    "y.size\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.where(y == 'Cammeo', -1, 1) # realizado o tratamento do classe categorica (string -> int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.dtypes.Float64DType'>\n"
     ]
    }
   ],
   "source": [
    "# X = df.iloc[0:, [2,3]].values # atributos utilizados\n",
    "# X.size\n",
    "\n",
    "X = df.iloc[0:, [1,2,3]].values # atributos utilizados\n",
    "print(type(X.dtype))\n",
    "# X\n",
    "# X = X.round(decimals=3)\n",
    "# X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando a base em treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=102) # 80% treinamento 20% teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objeto Neuronio, seus atributos e métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "# classe Neuronio e aprendizado estocastico/online\n",
    "\n",
    "class Neuronio(object):\n",
    "\n",
    "    def __init__(self, eta=0.1, epocas=50, fativ='perceptron',showErro=False):\n",
    "        self.eta = eta\n",
    "        self.epocas = epocas\n",
    "        self.w_ = np.random.rand(1 + X.shape[1]) - 0.5\n",
    "        self.fativ = fativ\n",
    "        self.showErro = showErro\n",
    "        self.erro_ep = 0\n",
    "        self.SqError_ = []\n",
    "\n",
    "    def somat(self, X):\n",
    "        return self.w_[0] + np.dot(X, self.w_[1:])\n",
    "\n",
    "    def sinal(self, x):\n",
    "        return np.where(x >= 0.0, 1, -1)\n",
    "\n",
    "    def tanh(self, x):\n",
    "      return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def d_tanh(self, x):\n",
    "      return 1 - self.tanh(x) * self.tanh(x)\n",
    "\n",
    "    def ReLU(self, x):\n",
    "      return np.where(x > 0.0, x, 0.1*x)  #max(0, x) .... float\n",
    "\n",
    "    def d_ReLU(self, x):\n",
    "      return np.where(x > 0.0, 1, 0.1)\n",
    "\n",
    "    def predict(self,X):\n",
    "      if self.fativ == 'sinal' or self.fativ == 'perceptron':\n",
    "#        print(f\"sinalPredict={self.sinal(self.somat(X))}\")  # debug\n",
    "        return self.sinal(self.somat(X))\n",
    "      elif self.fativ == 'linear':\n",
    "        return self.somat(X)\n",
    "      elif self.fativ == 'tanh':\n",
    "        return self.tanh(self.somat(X))\n",
    "      elif self.fativ == 'ReLU':\n",
    "        return self.ReLU(self.somat(X))\n",
    "      else:\n",
    "        return 11\n",
    "\n",
    "    def deltaW(self, erro):\n",
    "      if self.fativ == 'sinal' or self.fativ == 'perceptron':\n",
    "        atualiza = self.eta * erro\n",
    "      elif self.fativ == 'linear':\n",
    "        atualiza = self.eta * erro\n",
    "      elif self.fativ == 'tanh':\n",
    "#        print(f\"> eta={self.eta} tanh={self.tanh(erro)} dtanh={self.d_tanh(erro)} erro={erro}\")\n",
    "        atualiza = self.eta * self.d_tanh(erro) * erro\n",
    "      elif self.fativ == 'ReLU':\n",
    "        atualiza = self.eta * self.d_ReLU(erro) * erro\n",
    "      else:\n",
    "        print(f\"Função de ativação '{self.fativ}' desconhecida\")\n",
    "        exit()\n",
    "      return atualiza\n",
    "\n",
    "    def treinaGD(self,X,y):\n",
    "      self.SqError_ = []\n",
    "      self.erros_classif_ = []\n",
    "      for ep in range(self.epocas):\n",
    "        erro_classif = 0\n",
    "        indices = np.arange(X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        Xs = X[indices]\n",
    "        ys = y[indices]\n",
    "        outputs = self.predict(Xs)\n",
    "        erros = (ys - outputs)\n",
    "       # print(outputs,erros)\n",
    "        erro_classif = np.where(ys*outputs < 0, 1, 0).sum()\n",
    "        self.erros_classif_.append(erro_classif)\n",
    "        if ep < (self.epocas-1):\n",
    "          self.w_[1:] += self.eta * Xs.T.dot(erros)\n",
    "          self.w_[0] += self.eta * erros.sum()\n",
    "        SqError = (erros**2).sum() / 2.0 # ou np.square(erros)/2\n",
    "        self.SqError_.append(SqError)\n",
    "        if self.showErro:\n",
    "          if ep == 0:\n",
    "            print(f\"{'Época':^10}\\tErro\")\n",
    "          else:\n",
    "            print(f\"{str(ep):^10}\\t{erro_classif}\")\n",
    "      return self\n",
    "\n",
    "    def treinaSGD(self, X, y):\n",
    "        self.erros_ = []\n",
    "        self.erros_classif_ = []\n",
    "        self.SqError_ = []\n",
    "        for ep in range(self.epocas):\n",
    "            erro_ep = 0\n",
    "            erro_classif = 0\n",
    "            SqError = 0\n",
    "\n",
    "            indices = np.arange(X.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            Xs = X[indices]\n",
    "            ys = y[indices]\n",
    "\n",
    "            for xi, target in zip(Xs, ys):\n",
    "              output = self.predict(xi)\n",
    "              erro = target - output\n",
    "              SqError += erro*erro\n",
    "              erro_ep += erro\n",
    "              if (float(target)*float(output)) < 0:\n",
    "                #print(f\"ep={ep} {xi} target={target} output={output} t*o={target*output}\") # debug\n",
    "                erro_classif += 1\n",
    "\n",
    "              if (ep < (self.epocas-1)):  #\n",
    "                atualizacao = self.deltaW(erro)\n",
    "                self.w_[0] +=  atualizacao * 1\n",
    "                self.w_[1:] +=  atualizacao * xi\n",
    "\n",
    "            self.erros_.append(erro_ep)\n",
    "            self.SqError_.append(SqError)\n",
    "            self.erros_classif_.append(erro_classif)\n",
    "            if self.showErro:\n",
    "              if ep == 0:\n",
    "                print(f\"{'Época':^10}\\tErro\")\n",
    "              else:\n",
    "                print(f\"{str(ep):^10}\\t{erro_classif}\")\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Época   \tErro\n",
      "    1     \t1341\n",
      "    2     \t1290\n",
      "    3     \t1159\n",
      "    4     \t1121\n",
      "    5     \t1102\n",
      "    6     \t1037\n",
      "    7     \t988\n",
      "    8     \t998\n",
      "    9     \t948\n",
      "    10    \t942\n",
      "    11    \t959\n",
      "    12    \t905\n",
      "    13    \t867\n",
      "    14    \t903\n",
      "    15    \t906\n",
      "    16    \t876\n",
      "    17    \t886\n",
      "    18    \t912\n",
      "    19    \t895\n",
      "    20    \t886\n",
      "    21    \t888\n",
      "    22    \t879\n",
      "    23    \t878\n",
      "    24    \t887\n",
      "    25    \t865\n",
      "    26    \t864\n",
      "    27    \t888\n",
      "    28    \t848\n",
      "    29    \t841\n",
      "    30    \t875\n",
      "    31    \t836\n",
      "    32    \t876\n",
      "    33    \t831\n",
      "    34    \t842\n",
      "    35    \t820\n",
      "    36    \t830\n",
      "    37    \t852\n",
      "    38    \t843\n",
      "    39    \t834\n",
      "    40    \t824\n",
      "    41    \t838\n",
      "    42    \t796\n",
      "    43    \t843\n",
      "    44    \t822\n",
      "    45    \t816\n",
      "    46    \t867\n",
      "    47    \t823\n",
      "    48    \t823\n",
      "    49    \t851\n",
      "    50    \t838\n",
      "    51    \t831\n",
      "    52    \t813\n",
      "    53    \t822\n",
      "    54    \t859\n",
      "    55    \t848\n",
      "    56    \t777\n",
      "    57    \t803\n",
      "    58    \t837\n",
      "    59    \t830\n",
      "    60    \t813\n",
      "    61    \t810\n",
      "    62    \t819\n",
      "    63    \t790\n",
      "    64    \t824\n",
      "    65    \t817\n",
      "    66    \t834\n",
      "    67    \t849\n",
      "    68    \t823\n",
      "    69    \t860\n",
      "    70    \t814\n",
      "    71    \t828\n",
      "    72    \t819\n",
      "    73    \t847\n",
      "    74    \t830\n",
      "    75    \t833\n",
      "    76    \t830\n",
      "    77    \t796\n",
      "    78    \t810\n",
      "    79    \t817\n",
      "    80    \t803\n",
      "    81    \t791\n",
      "    82    \t804\n",
      "    83    \t785\n",
      "    84    \t818\n",
      "    85    \t811\n",
      "    86    \t800\n",
      "    87    \t803\n",
      "    88    \t792\n",
      "    89    \t818\n",
      "    90    \t828\n",
      "    91    \t810\n",
      "    92    \t791\n",
      "    93    \t823\n",
      "    94    \t800\n",
      "    95    \t843\n",
      "    96    \t800\n",
      "    97    \t829\n",
      "    98    \t832\n",
      "    99    \t819\n",
      "   100    \t812\n",
      "   101    \t876\n",
      "   102    \t807\n",
      "   103    \t783\n",
      "   104    \t853\n",
      "   105    \t813\n",
      "   106    \t802\n",
      "   107    \t817\n",
      "   108    \t812\n",
      "   109    \t824\n",
      "   110    \t828\n",
      "   111    \t782\n",
      "   112    \t818\n",
      "   113    \t819\n",
      "   114    \t800\n",
      "   115    \t798\n",
      "   116    \t812\n",
      "   117    \t806\n",
      "   118    \t814\n",
      "   119    \t815\n",
      "   120    \t819\n",
      "   121    \t817\n",
      "   122    \t811\n",
      "   123    \t788\n",
      "   124    \t821\n",
      "   125    \t801\n",
      "   126    \t843\n",
      "   127    \t805\n",
      "   128    \t819\n",
      "   129    \t807\n",
      "   130    \t802\n",
      "   131    \t793\n",
      "   132    \t812\n",
      "   133    \t815\n",
      "   134    \t803\n",
      "   135    \t762\n",
      "   136    \t800\n",
      "   137    \t813\n",
      "   138    \t803\n",
      "   139    \t819\n",
      "   140    \t806\n",
      "   141    \t781\n",
      "   142    \t818\n",
      "   143    \t776\n",
      "   144    \t786\n",
      "   145    \t817\n",
      "   146    \t816\n",
      "   147    \t807\n",
      "   148    \t789\n",
      "   149    \t793\n",
      "   150    \t802\n",
      "   151    \t810\n",
      "   152    \t807\n",
      "   153    \t806\n",
      "   154    \t791\n",
      "   155    \t801\n",
      "   156    \t794\n",
      "   157    \t815\n",
      "   158    \t848\n",
      "   159    \t795\n",
      "   160    \t817\n",
      "   161    \t796\n",
      "   162    \t830\n",
      "   163    \t813\n",
      "   164    \t802\n",
      "   165    \t828\n",
      "   166    \t828\n",
      "   167    \t774\n",
      "   168    \t813\n",
      "   169    \t817\n",
      "   170    \t821\n",
      "   171    \t809\n",
      "   172    \t815\n",
      "   173    \t834\n",
      "   174    \t809\n",
      "   175    \t775\n",
      "   176    \t812\n",
      "   177    \t824\n",
      "   178    \t774\n",
      "   179    \t808\n",
      "   180    \t815\n",
      "   181    \t793\n",
      "   182    \t816\n",
      "   183    \t807\n",
      "   184    \t791\n",
      "   185    \t830\n",
      "   186    \t817\n",
      "   187    \t834\n",
      "   188    \t829\n",
      "   189    \t814\n",
      "   190    \t844\n",
      "   191    \t820\n",
      "   192    \t790\n",
      "   193    \t812\n",
      "   194    \t802\n",
      "   195    \t800\n",
      "   196    \t782\n",
      "   197    \t824\n",
      "   198    \t801\n",
      "   199    \t781\n",
      "   200    \t813\n",
      "   201    \t803\n",
      "   202    \t800\n",
      "   203    \t801\n",
      "   204    \t770\n",
      "   205    \t786\n",
      "   206    \t809\n",
      "   207    \t788\n",
      "   208    \t822\n",
      "   209    \t823\n",
      "   210    \t834\n",
      "   211    \t800\n",
      "   212    \t801\n",
      "   213    \t786\n",
      "   214    \t819\n",
      "   215    \t810\n",
      "   216    \t800\n",
      "   217    \t775\n",
      "   218    \t777\n",
      "   219    \t804\n",
      "   220    \t814\n",
      "   221    \t825\n",
      "   222    \t804\n",
      "   223    \t813\n",
      "   224    \t809\n",
      "   225    \t767\n",
      "   226    \t763\n",
      "   227    \t778\n",
      "   228    \t803\n",
      "   229    \t816\n",
      "   230    \t817\n",
      "   231    \t797\n",
      "   232    \t818\n",
      "   233    \t799\n",
      "   234    \t826\n",
      "   235    \t787\n",
      "   236    \t813\n",
      "   237    \t787\n",
      "   238    \t790\n",
      "   239    \t809\n",
      "   240    \t812\n",
      "   241    \t805\n",
      "   242    \t823\n",
      "   243    \t790\n",
      "   244    \t806\n",
      "   245    \t808\n",
      "   246    \t797\n",
      "   247    \t780\n",
      "   248    \t800\n",
      "   249    \t815\n",
      "   250    \t795\n",
      "   251    \t795\n",
      "   252    \t779\n",
      "   253    \t805\n",
      "   254    \t790\n",
      "   255    \t808\n",
      "   256    \t819\n",
      "   257    \t801\n",
      "   258    \t782\n",
      "   259    \t822\n",
      "   260    \t788\n",
      "   261    \t843\n",
      "   262    \t827\n",
      "   263    \t790\n",
      "   264    \t794\n",
      "   265    \t825\n",
      "   266    \t801\n",
      "   267    \t785\n",
      "   268    \t791\n",
      "   269    \t782\n",
      "   270    \t795\n",
      "   271    \t797\n",
      "   272    \t816\n",
      "   273    \t816\n",
      "   274    \t795\n",
      "   275    \t814\n",
      "   276    \t792\n",
      "   277    \t794\n",
      "   278    \t829\n",
      "   279    \t805\n",
      "   280    \t807\n",
      "   281    \t822\n",
      "   282    \t826\n",
      "   283    \t798\n",
      "   284    \t810\n",
      "   285    \t798\n",
      "   286    \t789\n",
      "   287    \t798\n",
      "   288    \t767\n",
      "   289    \t788\n",
      "   290    \t779\n",
      "   291    \t796\n",
      "   292    \t800\n",
      "   293    \t787\n",
      "   294    \t813\n",
      "   295    \t808\n",
      "   296    \t786\n",
      "   297    \t781\n",
      "   298    \t801\n",
      "   299    \t692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Neuronio at 0x18adbc75190>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_ = []\n",
    "W0_ = []\n",
    "\n",
    "np.random.seed(35)\n",
    "classifier = Neuronio(fativ='tanh', eta=0.0001, epocas=300, showErro=True)\n",
    "W0 = classifier.w_.copy()\n",
    "W0_.append(W0)\n",
    "classifier.treinaSGD(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.08398950131233"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classifier.predict(X_test)\n",
    "PercClassifica = (100 * np.where(pred*y_test < 0, 0, 1).sum() / len(y_test))\n",
    "PercClassifica\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
