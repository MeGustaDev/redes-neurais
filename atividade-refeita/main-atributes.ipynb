{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando diferentes atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Info:\n",
    "Nome: Rice Dataset (Commeo and Osmancik)     \n",
    "Resumo: Um total de 3810 imagens de grãos de arroz foram tiradas de duas espécies (Cammeo e Osmancik).      \n",
    "- As imagens foram pré-processadas e certos atributos foram inferidos     \n",
    "- Sete atributos morfológicos foram obtidos para cada imagem de grão de arroz\n",
    "    - Area (integer)\n",
    "    - Perimeter (float)\n",
    "    - Major_Axis_Length (float)\n",
    "    - Minor_Axis_Length (float)\n",
    "    - Eccentricity (float)\n",
    "    - Extent (float)\n",
    "- Classes:\n",
    "    - Cammeo\n",
    "    - Osmancik\n",
    "\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rice.csv', header=None)\n",
    "\n",
    "y = df.iloc[0:, 7].values\n",
    "\n",
    "# Esse trecho de código é uma tentativa de evitar o overflow \n",
    "# quando se usa determinados parâmetros\n",
    "# Ainda não consegui resolver o problema\n",
    "\n",
    "# X = df.iloc[0:, [0,1,2,3,4,5,6]].values\n",
    "\n",
    "# for i, label in enumerate(X):\n",
    "#     print(i)\n",
    "#     print(X[i])\n",
    "#     label[0] = label[0] / 10000\n",
    "#     label[1] = label[1] / 100\n",
    "#     label[2] = label[2] / 100\n",
    "#     label[3] = label[3] / 10\n",
    "#     label[5] = label[5] / 10000\n",
    "#     print(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.where(y == 'Cammeo', -1, 1) # realizado o tratamento do classe categorica (string -> int)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objeto Neuronio, seus atributos e métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "# classe Neuronio e aprendizado estocastico/online\n",
    "\n",
    "class Neuronio(object):\n",
    "\n",
    "    def __init__(self, eta=0.1, epocas=50, fativ='perceptron',showErro=False):\n",
    "        self.eta = eta\n",
    "        self.epocas = epocas\n",
    "        self.w_ = np.random.rand(1 + X.shape[1]) - 0.5\n",
    "        self.fativ = fativ\n",
    "        self.showErro = showErro\n",
    "        self.erro_ep = 0\n",
    "        self.SqError_ = []\n",
    "\n",
    "    def somat(self, X):\n",
    "        return self.w_[0] + np.dot(X, self.w_[1:])\n",
    "\n",
    "    def sinal(self, x):\n",
    "        return np.where(x >= 0.0, 1, -1)\n",
    "\n",
    "    def tanh(self, x):\n",
    "      return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def d_tanh(self, x):\n",
    "      return 1 - self.tanh(x) * self.tanh(x)\n",
    "\n",
    "    def ReLU(self, x):\n",
    "      return np.where(x > 0.0, x, 0.1*x)  #max(0, x) .... float\n",
    "\n",
    "    def d_ReLU(self, x):\n",
    "      return np.where(x > 0.0, 1, 0.1)\n",
    "\n",
    "    def predict(self,X):\n",
    "      if self.fativ == 'sinal' or self.fativ == 'perceptron':\n",
    "#        print(f\"sinalPredict={self.sinal(self.somat(X))}\")  # debug\n",
    "        return self.sinal(self.somat(X))\n",
    "      elif self.fativ == 'linear':\n",
    "        return self.somat(X)\n",
    "      elif self.fativ == 'tanh':\n",
    "        return self.tanh(self.somat(X))\n",
    "      elif self.fativ == 'ReLU':\n",
    "        return self.ReLU(self.somat(X))\n",
    "      else:\n",
    "        return 11\n",
    "\n",
    "    def deltaW(self, erro):\n",
    "      if self.fativ == 'sinal' or self.fativ == 'perceptron':\n",
    "        atualiza = self.eta * erro\n",
    "      elif self.fativ == 'linear':\n",
    "        atualiza = self.eta * erro\n",
    "      elif self.fativ == 'tanh':\n",
    "#        print(f\"> eta={self.eta} tanh={self.tanh(erro)} dtanh={self.d_tanh(erro)} erro={erro}\")\n",
    "        atualiza = self.eta * self.d_tanh(erro) * erro\n",
    "      elif self.fativ == 'ReLU':\n",
    "        atualiza = self.eta * self.d_ReLU(erro) * erro\n",
    "      else:\n",
    "        print(f\"Função de ativação '{self.fativ}' desconhecida\")\n",
    "        exit()\n",
    "      return atualiza\n",
    "\n",
    "    def treinaGD(self,X,y):\n",
    "      self.SqError_ = []\n",
    "      self.erros_classif_ = []\n",
    "      for ep in range(self.epocas):\n",
    "        erro_classif = 0\n",
    "        indices = np.arange(X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        Xs = X[indices]\n",
    "        ys = y[indices]\n",
    "        outputs = self.predict(Xs)\n",
    "        erros = (ys - outputs)\n",
    "       # print(outputs,erros)\n",
    "        erro_classif = np.where(ys*outputs < 0, 1, 0).sum()\n",
    "        self.erros_classif_.append(erro_classif)\n",
    "        if ep < (self.epocas-1):\n",
    "          self.w_[1:] += self.eta * Xs.T.dot(erros)\n",
    "          self.w_[0] += self.eta * erros.sum()\n",
    "        SqError = (erros**2).sum() / 2.0 # ou np.square(erros)/2\n",
    "        self.SqError_.append(SqError)\n",
    "        if self.showErro:\n",
    "          if ep == 0:\n",
    "            print(f\"{'Época':^10}\\tErro\")\n",
    "          else:\n",
    "            print(f\"{str(ep):^10}\\t{erro_classif}\")\n",
    "      return self\n",
    "\n",
    "    def treinaSGD(self, X, y):\n",
    "        self.erros_ = []\n",
    "        self.erros_classif_ = []\n",
    "        self.SqError_ = []\n",
    "        for ep in range(self.epocas):\n",
    "            erro_ep = 0\n",
    "            erro_classif = 0\n",
    "            SqError = 0\n",
    "\n",
    "            indices = np.arange(X.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            Xs = X[indices]\n",
    "            ys = y[indices]\n",
    "\n",
    "            for xi, target in zip(Xs, ys):\n",
    "              output = self.predict(xi)\n",
    "              erro = target - output\n",
    "              SqError += erro*erro\n",
    "              erro_ep += erro\n",
    "              if (float(target)*float(output)) < 0:\n",
    "                #print(f\"ep={ep} {xi} target={target} output={output} t*o={target*output}\") # debug\n",
    "                erro_classif += 1\n",
    "\n",
    "              if (ep < (self.epocas-1)):  #\n",
    "                atualizacao = self.deltaW(erro)\n",
    "                self.w_[0] +=  atualizacao * 1\n",
    "                self.w_[1:] +=  atualizacao * xi\n",
    "\n",
    "            self.erros_.append(erro_ep)\n",
    "            self.SqError_.append(SqError)\n",
    "            self.erros_classif_.append(erro_classif)\n",
    "            if self.showErro:\n",
    "              if ep == 0:\n",
    "                print(f\"{'Época':^10}\\tErro\")\n",
    "              else:\n",
    "                print(f\"{str(ep):^10}\\t{erro_classif}\")\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributos selecionados[2, 3]\n",
      "Porcentagem de acertos: 79.27%\n",
      "Atributos selecionados[2, 3, 4]\n",
      "Porcentagem de acertos: 79.4%\n",
      "Atributos selecionados[2, 3, 4, 6]\n",
      "Porcentagem de acertos: 79.13%\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "W0_ = []\n",
    "atributes_selected = [[2,3], [2,3,4], [2,3,4,6]]\n",
    "# atributes_selected = [[1,2,3,4,5,6], [2,3]]\n",
    "\n",
    "for atributes in atributes_selected:\n",
    "    print(\"Atributos selecionados\" + str(atributes))\n",
    "\n",
    "    X = df.iloc[0:, atributes].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=102)\n",
    "\n",
    "    np.random.seed(35)\n",
    "    classifier = Neuronio(fativ='tanh', eta=0.0001, epocas=300, showErro=False)\n",
    "    W0 = classifier.w_.copy()\n",
    "    W0_.append(W0)\n",
    "    classifier.treinaSGD(X_train, y_train)\n",
    "    classifiers.append(classifier)\n",
    "\n",
    "    pred = classifier.predict(X_test)\n",
    "    PercClassifica = (100 * np.where(pred*y_test < 0, 0, 1).sum() / len(y_test))\n",
    "    print(\"Porcentagem de acertos: \" + str(round(PercClassifica,2)) + \"%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
